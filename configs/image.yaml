# example yaml file

meta_path: data/image/test_image_captioner.jsonl # path for the meta data, the format is fixed for image and video
meta_folder: data/image # only for captioner
base_folder: intermediate_results/ # path to save the intermediate results
save_folder: results/ # path to save the generated images
image_key: image # key for the image in the meta data
text_key: text # key for the text in the meta data
video_key: video # key for the video in the meta data

steps:
  - type: ImageCaptioner
    name: LLaVACaptioner
    config: 
      model_path: /mnt/petrelfs/liuzheng/cjz/llava-1.5-7b-hf
      trust_remote_code: true
      tensor_parallel_size: 2
      max_model_len: 2048
      max_num_seqs: 128
      temperature: 0.7
      top_p: 0.9
      top_k: 50
      repetition_penalty: 1.2
      prompt: What is the content of this image?
      repeat_time: 5
      batch_size: 1000
  - type: ImageGenerator
    name: FLUXGenerator
    config:
      model_path: black-forest-labs/FLUX.1-dev
      height: 1024
      weight: 1024
      guidance_scale: 4.5
      num_inference_steps: 50
      max_sequence_length: 512
      batch_size: 1
      device: cuda
  # - type: ImageCaptioner
  #   name: LLaVANeXTCaptioner
  #   config:
  #     model_path: /mnt/petrelfs/liuzheng/cjz/llava-v1.6-mistral-7b-hf
  #     trust_remote_code: true
  #     tensor_parallel_size: 2
  #     max_model_len: 4096
  #     max_num_seqs: 128
  #     temperature: 0.7
  #     top_p: 0.9
  #     top_k: 50
  #     repetition_penalty: 1.2
  #     prompt: What is the content of this image?
  #     repeat_time: 5
  #     batch_size: 1000
  # - type: ImageCaptioner
  #   name: LLaVAOneVisionCaptioner
  #   config:
  #     model_path: /mnt/petrelfs/liuzheng/synth_vlm/playground/model/llava-onevision-qwen2-7b-ov-hf
  #     trust_remote_code: true
  #     tensor_parallel_size: 4
  #     max_model_len: 16384
  #     max_num_seqs: 128
  #     temperature: 0.7
  #     top_p: 0.9
  #     top_k: 50
  #     repetition_penalty: 1.2
  #     prompt: What is the content of this image?
  #     repeat_time: 5
  #     batch_size: 1000
  # - type: ImageCaptioner
  #   name: BLIPCaptioner
  #   config:
  #     model_path: /mnt/petrelfs/liuzheng/synth_vlm/playground/model/blip2-opt-2.7b
  #     trust_remote_code: true
  #     tensor_parallel_size: 4
  #     max_model_len: 2048
  #     max_num_seqs: 128
  #     temperature: 0.7
  #     top_p: 0.9
  #     top_k: 50
  #     repetition_penalty: 1.2
  #     prompt: What is the content of this image?
  #     repeat_time: 5
  #     batch_size: 1000
  # - type: ImageCaptioner
  #   name: QwenVLCaptioner
  #   config:
  #     model_path: /mnt/petrelfs/liuzheng/hub3/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/51c47430f97dd7c74aa1fa6825e68a813478097f
  #     trust_remote_code: true
  #     tensor_parallel_size: 4
  #     max_model_len: 2048
  #     max_num_seqs: 128
  #     temperature: 0.7
  #     top_p: 0.9
  #     top_k: 50
  #     repetition_penalty: 1.2
  #     prompt: What is the content of this image?
  #     repeat_time: 5
  #     batch_size: 1000
  # - type: ImageCaptioner
  #   name: MLLamaCaptioner
  #   config:
  #     model_path: /mnt/petrelfs/liuzheng/hub3/models--meta-llama--Llama-3.2-11B-Vision-Instruct/snapshots/075e8feb24b6a50981f6fdc161622f741a8760b1
  #     trust_remote_code: true
  #     tensor_parallel_size: 4
  #     max_model_len: 1024
  #     max_num_seqs: 128
  #     temperature: 0.7
  #     top_p: 0.9
  #     top_k: 50
  #     repetition_penalty: 1.2
  #     prompt: What is the content of this image?
  #     repeat_time: 5
  #     batch_size: 1000
  # - type: ImageCaptioner
  #   name: Phi3VCaptioner
  #   config:
  #     model_path: /mnt/petrelfs/liuzheng/synth_vlm/playground/model/Phi-3-vision-128k-instruct
  #     trust_remote_code: true
  #     num_crops: 16
  #     tensor_parallel_size: 4
  #     max_model_len: 4096
  #     max_num_seqs: 128
  #     temperature: 0.7
  #     top_p: 0.9
  #     top_k: 50
  #     repetition_penalty: 1.2
  #     prompt: What is the content of this image?
  #     repeat_time: 5
  #     batch_size: 1000
  # - type: ImageGenerator
  #   name: StableDiffusion3Generator
  #   config:
  #     model_path: stabilityai/stable-diffusion-3.5-larges
  #     height: 1024
  #     weight: 1024
  #     guidance_scale: 4.5
  #     num_inference_steps: 50
  #     max_sequence_length: 512
  #     batch_size: 1
  #     device: cuda
  - type: ImageCaptioner
    name: ImageAPICaptioner
    config:
      model: openai:gpt-4o
      api_key: api_kay
      base_url: base_url
      max_tokens: 256
      temperature: 0.2
      sys_prompt: You are a helpful assistant.
      prompt: What is the content of this image?
      repeat_time: 5
      batch_size: 1000
  - type: ImageGenerator
    name: ImageAPIGenerator
    config:
      model: openai:dall-e-3
      api_key: api_key
      api_url: api_url
      height: 1024
      width: 1024
      quality: standard

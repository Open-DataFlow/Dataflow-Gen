# example yaml file

meta_path: data/prompt/i2v.jsonl # path for the meta data, the format is fixed for image and video
save_folder: results/video # path to save the generated images
save_per_batch: false # only for captioner
# meta_folder: /mnt/petrelfs/liuzheng/synth_vlm/playground/train # only for captioner
steps:
  type: VideoGenerator
  name: CogVideoXGenerator
  config:
    model_path: "THUDM/CogVideoX-5b-I2V"
    num_videos_per_prompt: 1
    num_inference_steps: 50
    num_frames: 49
    guidance_scale: 6
  type: VideoGenerator
  name: I2VGenXLGenerator
  config:
    model_path: "rhymes-ai/Allegro"
    batch_size: 2
    subfolder: "vae"
    num_frames: 16
    num_inference_steps: 100
    guidance_scale: 7.5
    negative_prompt: ""
    max_sequence_length: 512
  type: VideoGenerator
  name: CogVideoXT2VGenerator
  config:
    batch_size: 2
    model_path: "THUDM/CogVideoX-2b"
    num_videos_per_prompt: 1
    num_inference_steps: 50
    num_frames: 49
    guidance_scale: 6
  type: VideoGenerator
  name: I2VGenXLGenerator
  config:
    model_path: "ali-vilab/i2vgen-xl"
    variant: "fp16"
  type: VideoGenerator
  name: SVDGenerator
  config:
    model_path: "stabilityai/stable-video-diffusion-img2vid-xt"
    batch_size: 2
    variant: "fp16"
    decode_chunk_size: 8
  type: VideoGenerator
  name: AnimateDiffGenerator
  config:
    model_path: "emilianJR/epiCRealism"
    batch_size: 2
    cpu_offload: True
    num_frames: 16
    num_inference_steps: 59
    guidance_scale: 7.5
  type: VideoGenerator
  name: ModelScopeT2VGenerator
  config:
    model_path: "damo-vilab/text-to-video-ms-1.7b"
    batch_size: 2
    variant: "fp16"